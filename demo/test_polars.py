import akshare as ak
import polars as pl
from datetime import datetime

def fetch_and_process_stock(symbol: str, start_date: str, end_date: str):
    # --- 1. è·å–æ•°æ® (IO å¯†é›†å‹) ---
    print(f"ğŸš€ æ­£åœ¨ä» AkShare è·å– {symbol} çš„æ•°æ®...")
    
    # stock_zh_a_hist æ˜¯è·å– A è‚¡æ—¥çº¿æœ€å¸¸ç”¨çš„æ¥å£
    # adjust="qfq" è¡¨ç¤ºå‰å¤æƒ (é‡åŒ–å›æµ‹é€šå¸¸ç”¨å‰å¤æƒ)
    df_pd = ak.stock_zh_a_hist(
        symbol=symbol, 
        period="daily", 
        start_date=start_date, 
        end_date=end_date, 
        adjust="qfq"
    )

    if df_pd.empty:
        print("âš ï¸ æœªè·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»£ç æˆ–æ—¥æœŸèŒƒå›´")
        return None

    # --- 2. è½¬æ¢ä¸º Polars å¹¶æ¸…æ´— (CPU å¯†é›†å‹) ---
    print("âš¡ æ­£åœ¨ä½¿ç”¨ Polars è¿›è¡Œé«˜æ€§èƒ½å¤„ç†...")
    
    # 2.1 è½¬æ¢ Pandas -> Polars
    df = pl.from_pandas(df_pd)

    # 2.2 å®šä¹‰åˆ—åæ˜ å°„ (ä¸­æ–‡ -> è‹±æ–‡ï¼Œæ–¹ä¾¿åç»­ä»£ç ç¼–å†™)
    # AkShare è¿”å›çš„åˆ—åé€šå¸¸æ˜¯ä¸­æ–‡
    column_mapping = {
        "æ—¥æœŸ": "date",
        "å¼€ç›˜": "open",
        "æ”¶ç›˜": "close",
        "æœ€é«˜": "high",
        "æœ€ä½": "low",
        "æˆäº¤é‡": "volume",
        "æˆäº¤é¢": "amount",
        "æŒ¯å¹…": "amplitude",
        "æ¶¨è·Œå¹…": "pct_chg_ak", # AkShare è‡ªå¸¦çš„æ¶¨è·Œå¹…ï¼Œæˆ‘ä»¬åé¢è‡ªå·±ç®—ä¸€ä¸ªéªŒè¯
        "æ¶¨è·Œé¢": "change",
        "æ¢æ‰‹ç‡": "turnover",
    }

    # 2.3 æ ¸å¿ƒå¤„ç†é€»è¾‘ (é“¾å¼è°ƒç”¨)
    processed_df = (
        df
        # [Rename] é‡å‘½ååˆ—
        .rename(column_mapping)
        
        # [Select] åªä¿ç•™éœ€è¦çš„åˆ—ï¼Œå»é™¤å¤šä½™çš„
        .select(["date", "open", "high", "low", "close", "volume"])
        
        # [Type Cast] ç±»å‹è½¬æ¢ï¼šæ—¥æœŸå­—ç¬¦ä¸² -> Date å¯¹è±¡, æ•°å€¼ -> Float64
        .with_columns([
            pl.col("date").cast(pl.Utf8).str.to_date("%Y-%m-%d"),
            pl.col("open").cast(pl.Float64),
            pl.col("close").cast(pl.Float64),
            pl.col("high").cast(pl.Float64),
            pl.col("low").cast(pl.Float64),
            pl.col("volume").cast(pl.Float64),
        ])
        
        # [Sort] ç¡®ä¿æŒ‰æ—¶é—´æ’åº (è™½ç„¶æ¥å£é€šå¸¸æ˜¯æ’å¥½çš„ï¼Œä½†ä¿é™©èµ·è§)
        .sort("date")
        
        # --- 3. é‡åŒ–å› å­è®¡ç®— (Vectorized Operations) ---
        .with_columns([
            # 3.1 ç§»åŠ¨å¹³å‡çº¿ (MA)
            pl.col("close").rolling_mean(window_size=5).alias("ma_5"),
            pl.col("close").rolling_mean(window_size=20).alias("ma_20"),
            
            # 3.2 å¯¹æ•°æ”¶ç›Šç‡ (Log Returns) -> ln(Pt / Pt-1)
            # åœ¨é‡‘èæ•°å­¦ä¸­ï¼Œå¯¹æ•°æ”¶ç›Šç‡æ¯”ç®€å•ç™¾åˆ†æ¯”æ›´ä¼˜ï¼Œå…·æœ‰å¯åŠ æ€§
            (pl.col("close") / pl.col("close").shift(1)).log().alias("log_return"),
            
            # 3.3 çœŸå®æ³¢åŠ¨ç‡ (ATR çš„ç®€åŒ–ç‰ˆ - ä»…åšæ¼”ç¤ºï¼Œè®¡ç®— 20æ—¥æ ‡å‡†å·®)
            pl.col("close")
              .rolling_std(window_size=20)
              .alias("volatility_20")
        ])
        
        # [Filter] å»é™¤å‰é¢å› ä¸º rolling è®¡ç®—äº§ç”Ÿçš„ Null å€¼ (å‰20è¡Œ)
        .drop_nulls()
    )

    return processed_df

if __name__ == "__main__":
    # è·å– 2023å¹´è‡³ä»Šçš„æ•°æ®
    symbol = "600519" # è´µå·èŒ…å°
    start_date = "20230101"
    end_date = datetime.now().strftime("%Y%m%d")

    df = fetch_and_process_stock(symbol, start_date, end_date)

    if df is not None:
        # è®¾ç½® Polars æ˜¾ç¤ºæ ¼å¼ï¼Œé˜²æ­¢ä¸­é—´è¢«çœç•¥
        pl.Config.set_tbl_rows(10) 
        print(f"\nğŸ“Š {symbol} å¤„ç†ç»“æœé¢„è§ˆ:")
        print(df)
        
        # è¿˜å¯ä»¥ç›´æ¥è½¬ä¸º Parquet å­˜ç›˜ï¼Œé€Ÿåº¦æå¿«
        df.write_parquet("kline_data.parquet")
        df.write_csv("kline_data.csv")